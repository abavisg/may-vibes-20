# CFP Scout
AI-powered agent system for discovering relevant tech conference CFPs

**CFP Scout** is a fully Dockerized AI-powered agent system that scrapes tech events with open CFPs, filters them using a language model based on user-defined interests, and sends daily email notifications at 8am UK time with the most relevant results.

---

## Features

- **ğŸ” Smart Scraping** â€“ Automatically scrapes CFP events from confs.tech/cfp using Selenium
- **ğŸ¯ Event MCP Agent** â€“ Central orchestrator that normalizes, deduplicates, and manages event data flow
- **ğŸ¤– AI Filtering** â€“ Uses OpenAI GPT-4 to filter events based on user interests (AI, engineering leadership, fintech, developer experience)
- **ğŸ“§ Daily Notifications** â€“ Sends formatted emails with relevant CFPs every day at 8am UK time
- **ğŸ³ Fully Dockerized** â€“ Easy deployment with Docker container
- **ğŸ›¡ï¸ Error Handling** â€“ Robust error handling and logging throughout the pipeline
- **ğŸ”„ Deduplication** â€“ Automatic duplicate event detection and removal

---

## Tech Stack

- **Python 3.11** â€“ Core application language
- **Selenium/Chrome** â€“ Web scraping for JavaScript-rendered content
- **OpenAI GPT-4** â€“ Event filtering and relevance scoring
- **SMTP/Gmail** â€“ Email delivery
- **Docker** â€“ Containerization
- **JSON** â€“ Data storage and interchange

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scraper(s)    â”‚â”€â”€â”€â–¶â”‚   Event MCP     â”‚â”€â”€â”€â–¶â”‚   CFP Filter    â”‚â”€â”€â”€â–¶â”‚   Email Sender  â”‚
â”‚   (scraper.py)  â”‚    â”‚  (event_mcp.py) â”‚    â”‚   Agent         â”‚    â”‚(email_sender.py)â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚(cfp_filter_agentâ”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â€¢ Normalize    â”‚    â”‚     .py)        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚  â€¢ Deduplicate  â”‚    â”‚                 â”‚             â”‚
                       â”‚  â€¢ Store        â”‚    â”‚  â€¢ LLM Filter   â”‚             â–¼
                       â”‚  â€¢ Orchestrate  â”‚    â”‚  â€¢ Relevance    â”‚      ğŸ“§ Daily Email
                       â”‚                 â”‚â—€â”€â”€â”€â”‚    Scoring      â”‚         8am UK
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Main Schedulerâ”‚
                        â”‚    (main.py)    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Event MCP Agent** acts as the central orchestrator:
- âœ… Collects raw events from one or more scrapers
- âœ… Normalizes data into consistent structure
- âœ… Deduplicates events based on title + link
- âœ… Stores events at each pipeline stage (raw, normalized, filtered)
- âœ… Coordinates filtering and email processes
- âœ… Provides comprehensive error handling and logging

---

## Project Structure

```
cfp-scout/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py              # Event scraper agent (Selenium-based)
â”‚   â”œâ”€â”€ event_mcp.py            # Event MCP agent (central orchestrator)
â”‚   â”œâ”€â”€ cfp_filter_agent.py     # AI filtering agent  
â”‚   â”œâ”€â”€ email_sender.py         # Email notification agent
â”‚   â”œâ”€â”€ main.py                 # Main orchestrator
â”‚   â””â”€â”€ test_event_mcp.py       # Event MCP tests
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ raw_events.json         # Raw scraped events
â”‚   â”œâ”€â”€ normalized_events.json  # Normalized & deduplicated events
â”‚   â””â”€â”€ filtered_events.json    # LLM-filtered relevant events
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                  # Docker configuration
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ docker-compose.yml         # Docker compose setup
â””â”€â”€ README.md                  # This file
```

---

## Environment Variables

Create a `.env` file with the following variables:

```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Email Configuration  
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
EMAIL_ADDRESS=your_email@gmail.com
EMAIL_PASSWORD=your_app_password
TO_EMAIL=recipient@example.com

# User Interests for CFP Filtering (comma-separated)
USER_INTERESTS=AI,machine learning,artificial intelligence,engineering leadership,fintech,financial technology,developer experience,DevOps,software architecture,data engineering,cloud computing

# Scheduling Configuration
SCHEDULE_TIME=08:00
TIMEZONE=Europe/London

# Logging Configuration
LOG_LEVEL=INFO
```

---

## Setup the Application

### Prerequisites
- Docker and Docker Compose
- OpenAI API key
- Gmail account with App Password enabled

### Local Development Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd cfp-scout
   ```

2. **Create environment file**
   ```bash
   cp .env.example .env
   # Edit .env with your actual values
   ```

3. **Install dependencies (optional for local development)**
   ```bash
   pip install -r requirements.txt
   ```

### Docker Setup

1. **Build the Docker image**
   ```bash
   docker build -t cfp-scout .
   ```

2. **Run with Docker Compose**
   ```bash
   docker-compose up -d
   ```

---

## Run the Application

### Manual Run
```bash
# Run the complete pipeline
python src/event_mcp.py

# Run individual components
python src/scraper.py           # Scraper only
python src/test_event_mcp.py    # Run MCP tests
```

### Docker Run
```bash
docker run --env-file .env cfp-scout
```

### Scheduled Daily Execution
The application is designed to run daily at 8am UK time. Use your preferred scheduling method:

- **Docker Compose with cron**: Already configured in docker-compose.yml
- **Host cron**: Add cron job to run the Docker container
- **Cloud scheduler**: Use AWS EventBridge, Google Cloud Scheduler, etc.

---

## Development Progress

### âœ… Completed
- [x] Project structure and README setup
- [x] Event Scraper Agent (scraper.py) - Selenium-based scraping from confs.tech/cfp
- [x] Event MCP Agent (event_mcp.py) - Central orchestrator with normalization and deduplication

### ğŸš§ In Progress  
- [ ] CFP Filter Agent (cfp_filter_agent.py) - OpenAI GPT-4 filtering

### ğŸ“‹ Upcoming
- [ ] Email Sender Agent (email_sender.py)  
- [ ] Main Scheduler (main.py)
- [ ] Final Docker integration and testing

---

## Data Flow

1. **Scraping Phase**: Scraper agents collect raw CFP events
2. **MCP Phase**: Event MCP normalizes, deduplicates, and stores events
3. **Filtering Phase**: LLM filters events based on user interests  
4. **Notification Phase**: Email sender delivers relevant events

**Current Status**: Successfully scraping and processing **27 CFP events** with full deduplication and normalization.

---

## Future Improvements

- ğŸ¯ **Feedback Agent** â€“ Learn user preferences over time
- ğŸ’¬ **Slack/Telegram Integration** â€“ Multiple notification channels
- ğŸ“… **Calendar Sync** â€“ Auto-add deadlines to calendar
- ğŸ¨ **Web UI** â€“ Dashboard with historical logs and preferences
- ğŸ“Š **Analytics** â€“ Track CFP success rates and preferences
- ğŸ”Œ **Additional Scrapers** â€“ Support for more conference listing sites

---

## License
MIT

